1. I have started to work in Deep Learning from couple of months back due to my high interest. I have dome some background research as part of my Master level studies on this and
providing my knowledge here on the "DL_NLP_Theoretical_Background" report.


2. The "Word2Vec_Word_Similarity" is a task to use the WOrd2Vec model from Google Deep Learning API and use it to calculate the cosine similarity between words. This word
representation is helpful in many data processing especially for text mining and machine learning algorithms. If cosine distance is higher between two words then, they are more 
strongly related to each other. This representation is also called Thought Vector representation or Distributed representation of words or features.


3. A simple Feed-forward neural network using the "Keras" library has been shown just to demonstrate my skill in these areas. I also would like to mention that, I am still learning 
new Python libraries for both statistical data modelling, Deep learning and NLP too. I started with R language for data analysis and later on I have also got interests in Python.
